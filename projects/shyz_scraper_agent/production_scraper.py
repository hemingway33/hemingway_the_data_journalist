#!/usr/bin/env python3
"""
ä¸Šæµ·å°ç« ä¿¡æ¯æŸ¥è¯¢ç”Ÿäº§ç‰ˆçˆ¬è™«
åŸºäºæˆåŠŸçš„DrissionPageæ–¹æ¡ˆçš„ç”Ÿäº§å°±ç»ªç‰ˆæœ¬
"""

import os
import sys
import time
import logging
import csv
import json
from typing import List, Optional
from dataclasses import dataclass, asdict
from pathlib import Path

# å¯¼å…¥æˆ‘ä»¬å·²ç»éªŒè¯å¯å·¥ä½œçš„æ¨¡å—
from shyz_scraper_drission import SHYZScraperDrission, CompanyQuery, SealInfo

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ProductionScraper:
    """ç”Ÿäº§ç¯å¢ƒå°ç« ä¿¡æ¯çˆ¬è™«"""
    
    def __init__(self, headless: bool = True, timeout: int = 60, max_retries: int = 3):
        """
        åˆå§‹åŒ–ç”Ÿäº§çˆ¬è™«
        
        Args:
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œ
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        self.headless = headless
        self.timeout = timeout
        self.max_retries = max_retries
        self.scraper = None
        
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        self.initialize()
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()
        
    def initialize(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        try:
            logger.info("åˆå§‹åŒ–ç”Ÿäº§çˆ¬è™«")
            self.scraper = SHYZScraperDrission(
                headless=self.headless,
                timeout=self.timeout
            )
            logger.info("çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"çˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def search_with_retry(self, query: CompanyQuery) -> List[SealInfo]:
        """å¸¦é‡è¯•æœºåˆ¶çš„æŸ¥è¯¢"""
        last_error = None
        
        for attempt in range(1, self.max_retries + 1):
            try:
                logger.info(f"æŸ¥è¯¢ {query.company_name} - å°è¯• {attempt}/{self.max_retries}")
                
                results = self.scraper.search_company_seal(query)
                
                if results:
                    logger.info(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œè·å¾— {len(results)} æ¡è®°å½•")
                    return results
                else:
                    logger.warning(f"âŒ æŸ¥è¯¢æ— ç»“æœ")
                    
                    # å¦‚æœæ²¡æœ‰ç»“æœä½†æ²¡æœ‰å¼‚å¸¸ï¼Œä¸éœ€è¦é‡è¯•
                    if attempt == 1:
                        return []
                    
            except Exception as e:
                last_error = e
                logger.error(f"æŸ¥è¯¢å¤±è´¥ (å°è¯• {attempt}/{self.max_retries}): {e}")
                
                if attempt < self.max_retries:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    
                    # é‡æ–°åˆå§‹åŒ–scraperä»¥é˜²æ­¢çŠ¶æ€é—®é¢˜
                    try:
                        self.scraper.close()
                        self.scraper = SHYZScraperDrission(
                            headless=self.headless,
                            timeout=self.timeout
                        )
                    except:
                        pass
        
        logger.error(f"æŸ¥è¯¢ {query.company_name} æœ€ç»ˆå¤±è´¥: {last_error}")
        return []
    
    def batch_search(self, queries: List[CompanyQuery], 
                    progress_callback=None) -> List[SealInfo]:
        """æ‰¹é‡æŸ¥è¯¢"""
        try:
            logger.info(f"å¼€å§‹æ‰¹é‡æŸ¥è¯¢ {len(queries)} ä¸ªå…¬å¸")
            
            all_results = []
            success_count = 0
            error_count = 0
            
            for i, query in enumerate(queries, 1):
                try:
                    if progress_callback:
                        progress_callback(i, len(queries), query.company_name)
                    
                    logger.info(f"è¿›åº¦: {i}/{len(queries)} - {query.company_name}")
                    
                    results = self.search_with_retry(query)
                    all_results.extend(results)
                    
                    if results:
                        success_count += 1
                        logger.info(f"âœ… {query.company_name}: {len(results)} æ¡è®°å½•")
                    else:
                        logger.warning(f"âš ï¸ {query.company_name}: æ— è®°å½•")
                    
                    # è¯·æ±‚é—´éš”ï¼Œé¿å…è¿‡äºé¢‘ç¹
                    if i < len(queries):
                        time.sleep(1)
                        
                except Exception as e:
                    error_count += 1
                    logger.error(f"âŒ {query.company_name} æŸ¥è¯¢å¼‚å¸¸: {e}")
                    continue
            
            logger.info(f"æ‰¹é‡æŸ¥è¯¢å®Œæˆ:")
            logger.info(f"  æ€»å…¬å¸æ•°: {len(queries)}")
            logger.info(f"  æˆåŠŸæŸ¥è¯¢: {success_count}")
            logger.info(f"  æŸ¥è¯¢å¼‚å¸¸: {error_count}")
            logger.info(f"  æ€»è®°å½•æ•°: {len(all_results)}")
            
            return all_results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡æŸ¥è¯¢å¤±è´¥: {e}")
            return []
    
    def close(self):
        """å…³é—­çˆ¬è™«"""
        try:
            if self.scraper:
                self.scraper.close()
                logger.info("çˆ¬è™«å·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­çˆ¬è™«å¤±è´¥: {e}")

def load_companies_from_csv(file_path: str) -> List[CompanyQuery]:
    """ä»CSVæ–‡ä»¶åŠ è½½å…¬å¸ä¿¡æ¯"""
    try:
        queries = []
        
        with open(file_path, 'r', encoding='utf-8') as csvfile:
            # å°è¯•æ£€æµ‹åˆ†éš”ç¬¦
            sample = csvfile.read(1024)
            csvfile.seek(0)
            
            sniffer = csv.Sniffer()
            delimiter = sniffer.sniff(sample).delimiter
            
            reader = csv.DictReader(csvfile, delimiter=delimiter)
            
            for i, row in enumerate(reader, 1):
                try:
                    # å°è¯•ä¸åŒçš„åˆ—åæ ¼å¼
                    company_name = (
                        row.get('company_name') or 
                        row.get('å…¬å¸åç§°') or 
                        row.get('å•ä½åç§°') or
                        row.get('ä¼ä¸šåç§°') or
                        ''
                    ).strip()
                    
                    credit_code = (
                        row.get('credit_code') or
                        row.get('social_credit_code') or
                        row.get('ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç ') or
                        row.get('ä¿¡ç”¨ä»£ç ') or
                        ''
                    ).strip()
                    
                    if company_name and credit_code:
                        queries.append(CompanyQuery(
                            company_name=company_name,
                            credit_code=credit_code
                        ))
                    else:
                        logger.warning(f"ç¬¬ {i} è¡Œæ•°æ®ä¸å®Œæ•´: å…¬å¸åç§°='{company_name}', ä¿¡ç”¨ä»£ç ='{credit_code}'")
                        
                except Exception as e:
                    logger.error(f"è§£æç¬¬ {i} è¡Œå¤±è´¥: {e}")
                    continue
        
        logger.info(f"ä» {file_path} æˆåŠŸåŠ è½½ {len(queries)} ä¸ªå…¬å¸")
        
        if not queries:
            logger.error("æœªèƒ½åŠ è½½ä»»ä½•æœ‰æ•ˆçš„å…¬å¸æ•°æ®")
            logger.info("è¯·ç¡®ä¿CSVæ–‡ä»¶åŒ…å«ä»¥ä¸‹åˆ—åä¹‹ä¸€ï¼š")
            logger.info("  å…¬å¸åç§°: company_name, å…¬å¸åç§°, å•ä½åç§°, ä¼ä¸šåç§°")
            logger.info("  ä¿¡ç”¨ä»£ç : credit_code, social_credit_code, ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç , ä¿¡ç”¨ä»£ç ")
        
        return queries
        
    except Exception as e:
        logger.error(f"åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
        return []

def save_results_to_csv(results: List[SealInfo], output_file: str):
    """ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶"""
    try:
        with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['company_name', 'credit_code', 'seal_name', 'registration_date', 'seal_status', 'query_time']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            # å†™å…¥ä¸­æ–‡åˆ—æ ‡é¢˜
            chinese_headers = {
                'company_name': 'å…¬å¸åç§°',
                'credit_code': 'ç»Ÿä¸€ç¤¾ä¼šä¿¡ç”¨ä»£ç ', 
                'seal_name': 'å°ç« åç§°',
                'registration_date': 'å¤‡æ¡ˆæ—¥æœŸ',
                'seal_status': 'å°ç« çŠ¶æ€',
                'query_time': 'æŸ¥è¯¢æ—¶é—´'
            }
            writer.writerow(chinese_headers)
            
            # å†™å…¥æ•°æ®
            for result in results:
                writer.writerow(asdict(result))
        
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ° {output_file}")
        
    except Exception as e:
        logger.error(f"ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")

def save_results_to_json(results: List[SealInfo], output_file: str):
    """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
    try:
        data = {
            'query_time': time.strftime("%Y-%m-%d %H:%M:%S"),
            'total_records': len(results),
            'results': [asdict(result) for result in results]
        }
        
        with open(output_file, 'w', encoding='utf-8') as jsonfile:
            json.dump(data, jsonfile, ensure_ascii=False, indent=2)
        
        logger.info(f"JSONç»“æœå·²ä¿å­˜åˆ° {output_file}")
        
    except Exception as e:
        logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥: {e}")

def create_summary_report(results: List[SealInfo], output_file: str):
    """åˆ›å»ºæŸ¥è¯¢æ±‡æ€»æŠ¥å‘Š"""
    try:
        # ç»Ÿè®¡ä¿¡æ¯
        total_companies = len(set(result.company_name for result in results))
        total_seals = len(results)
        
        # æŒ‰å…¬å¸åˆ†ç»„
        company_stats = {}
        for result in results:
            company = result.company_name
            if company not in company_stats:
                company_stats[company] = []
            company_stats[company].append(result)
        
        # å°ç« ç±»å‹ç»Ÿè®¡
        seal_type_stats = {}
        for result in results:
            seal_type = result.seal_name
            seal_type_stats[seal_type] = seal_type_stats.get(seal_type, 0) + 1
        
        # ç”ŸæˆæŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("# ä¸Šæµ·å°ç« ä¿¡æ¯æŸ¥è¯¢æ±‡æ€»æŠ¥å‘Š\n\n")
            f.write(f"æŸ¥è¯¢æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## æ€»ä½“ç»Ÿè®¡\n")
            f.write(f"- æŸ¥è¯¢å…¬å¸æ•°: {total_companies}\n")
            f.write(f"- å°ç« è®°å½•æ•°: {total_seals}\n")
            f.write(f"- å¹³å‡æ¯å…¬å¸å°ç« æ•°: {total_seals/total_companies if total_companies > 0 else 0:.1f}\n\n")
            
            f.write("## å°ç« ç±»å‹åˆ†å¸ƒ\n")
            for seal_type, count in sorted(seal_type_stats.items(), key=lambda x: x[1], reverse=True):
                f.write(f"- {seal_type}: {count} ä¸ª\n")
            f.write("\n")
            
            f.write("## å…¬å¸è¯¦æƒ…\n")
            for company, seals in sorted(company_stats.items()):
                f.write(f"### {company}\n")
                f.write(f"ä¿¡ç”¨ä»£ç : {seals[0].credit_code}\n")
                f.write(f"å°ç« æ•°é‡: {len(seals)}\n")
                for seal in seals:
                    f.write(f"- {seal.seal_name} ({seal.registration_date}, {seal.seal_status})\n")
                f.write("\n")
        
        logger.info(f"æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜åˆ° {output_file}")
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")

def progress_callback(current: int, total: int, company_name: str):
    """è¿›åº¦å›è°ƒå‡½æ•°"""
    percentage = (current / total) * 100
    print(f"\rè¿›åº¦: {current}/{total} ({percentage:.1f}%) - {company_name[:20]}", end='', flush=True)

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ä¸Šæµ·å°ç« ä¿¡æ¯æŸ¥è¯¢ç”Ÿäº§ç‰ˆçˆ¬è™«')
    parser.add_argument('input_file', help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶å‰ç¼€', default='results')
    parser.add_argument('--headless', action='store_true', help='æ— å¤´æ¨¡å¼è¿è¡Œ')
    parser.add_argument('--timeout', type=int, default=60, help='è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--retries', type=int, default=3, help='æœ€å¤§é‡è¯•æ¬¡æ•°')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input_file):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input_file}")
        sys.exit(1)
    
    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    base_name = Path(args.input_file).stem
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    
    csv_output = f"{args.output}_{base_name}_{timestamp}.csv"
    json_output = f"{args.output}_{base_name}_{timestamp}.json"
    report_output = f"{args.output}_{base_name}_{timestamp}_report.md"
    
    try:
        # åŠ è½½æŸ¥è¯¢æ•°æ®
        print(f"ğŸ“ åŠ è½½è¾“å…¥æ–‡ä»¶: {args.input_file}")
        queries = load_companies_from_csv(args.input_file)
        
        if not queries:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æŸ¥è¯¢æ•°æ®")
            sys.exit(1)
        
        print(f"âœ… åŠ è½½äº† {len(queries)} ä¸ªå…¬å¸")
        
        # æ‰§è¡ŒæŸ¥è¯¢
        print(f"ğŸ” å¼€å§‹æŸ¥è¯¢...")
        
        with ProductionScraper(
            headless=args.headless,
            timeout=args.timeout,
            max_retries=args.retries
        ) as scraper:
            
            results = scraper.batch_search(queries, progress_callback)
        
        print(f"\n\nğŸ‰ æŸ¥è¯¢å®Œæˆ!")
        print(f"ğŸ“Š è·å¾— {len(results)} æ¡å°ç« è®°å½•")
        
        if results:
            # ä¿å­˜ç»“æœ
            print(f"ğŸ’¾ ä¿å­˜ç»“æœ...")
            save_results_to_csv(results, csv_output)
            save_results_to_json(results, json_output)
            create_summary_report(results, report_output)
            
            print(f"âœ… è¾“å‡ºæ–‡ä»¶:")
            print(f"   ğŸ“„ CSV: {csv_output}")
            print(f"   ğŸ“„ JSON: {json_output}")
            print(f"   ğŸ“„ æŠ¥å‘Š: {report_output}")
        else:
            print("âš ï¸ æ²¡æœ‰è·å¾—ä»»ä½•å°ç« è®°å½•")
    
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ ç”¨æˆ·ä¸­æ–­æŸ¥è¯¢")
        sys.exit(1)
    except Exception as e:
        logger.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 